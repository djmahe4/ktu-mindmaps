Okay, here is a question bank with answers for the CST202 Computer Organization and Architecture course, organized by module based on the syllabus provided and incorporating questions from the attached PDF exam papers.---\*\*Question Bank: CST202 Computer Organization and Architecture\*\*\*\*Module 1: Basic Structure, Memory, Instructions, Addressing Modes, Basic Processing Unit\*\*\*\*(Syllabus Topics:\*\* Functional units, operational concepts, bus structures, memory locations/addresses/operations, instructions/sequencing, addressing modes, fundamental concepts (processing unit), instruction cycle, execution of complete instruction, single/multiple bus organization.)\*\*Short Answer Questions (Typically 3 Marks)\*\*1. \*\*Q:\*\* Define three, two and one-address instructions with one example for each. (June 2023 Sup Q1) \*\*A:\*\* \* \*\*Three-address:\*\* Specifies two source operands and one destination. Ex: \`ADD DST, SRC1, SRC2\` (DST <- \[SRC1\] + \[SRC2\]). Requires longer instruction format. \* \*\*Two-address:\*\* One operand serves as both source and destination. Ex: \`ADD DST, SRC\` (DST <- \[DST\] + \[SRC\]). Common format. \* \*\*One-address:\*\* Implicitly uses an accumulator register (AC). Ex: \`ADD SRC\` (AC <- \[AC\] + \[SRC\]). Requires fewer bits but more instructions.2. \*\*Q:\*\* Why is the Wait-for-Memory-Function-Completed (MFC) step required when performing memory transfer operations? (June 2023 Sup Q2) \*\*A:\*\* Memory access time is usually much slower than the processor speed. The MFC signal is used to synchronize the processor with the memory. The processor initiates a memory read/write and waits until the memory signals (via MFC) that the operation is complete before proceeding, ensuring data integrity.3. \*\*Q:\*\* With a neat diagram explain the internal architecture of CPU? (June 2023 Reg Q1) \*\*A:\*\* The internal architecture of a CPU typically includes: \* \*\*ALU (Arithmetic Logic Unit):\*\* Performs arithmetic and logical operations. \* \*\*Control Unit (CU):\*\* Generates control signals to coordinate CPU operations. \* \*\*Registers:\*\* \* PC (Program Counter): Holds the address of the next instruction. \* IR (Instruction Register): Holds the currently executing instruction. \* MAR (Memory Address Register): Holds the address of the memory location to be accessed. \* MDR (Memory Data Register): Holds the data being transferred to/from memory. \* General Purpose Registers (GPRs): Used for temporary data storage (e.g., R0, R1...). \* \*\*Internal Bus:\*\* Connects the internal components (ALU, Registers, CU). \*(A simple block diagram showing these components and their interconnections via buses should be drawn).\*4. \*\*Q:\*\* Enumerate the sequence of actions (control signals) involved in executing an unconditional branch instruction? (June 2023 Reg Q2) \*\*A:\*\* Assuming a branch instruction like \`BR Target\_Address\` (where Target\_Address is part of the instruction): 1. Instruction Fetch (already done). 2. Decode: CU recognizes it's an unconditional branch. 3. Address Calculation: Extract \`Target\_Address\` from the IR. 4. PC Update: Load \`Target\_Address\` into the PC. (Control signal: \`IR\_offset\_out\`, \`PC\_in\`, \`Load\_PC\`). The next instruction fetch cycle will use this new PC value.5. \*\*Q:\*\* Compare auto increment and auto decrement addressing modes with examples. (July 2021 Q1, June 2022 Q1) \*\*A:\*\* \* \*\*Auto Increment:\*\* The effective address is the content of the specified register. After accessing the operand, the register content is automatically incremented (usually by the size of the operand). Ex: \`MOV R1, (R2)+\`. If R2 holds 1000, data is fetched from address 1000, and then R2 becomes 1004 (assuming 4-byte words). Useful for accessing sequential data forward. \* \*\*Auto Decrement:\*\* The content of the specified register is first automatically decremented (usually by the size of the operand), and the new content is the effective address. Ex: \`MOV R1, -(R2)\`. If R2 holds 1004, it becomes 1000, and then data is fetched from address 1000. Useful for stack operations or accessing sequential data backward.6. \*\*Q:\*\* Outline the steps involved in the execution of an instruction. (July 2021 Q2) \*\*A:\*\* The basic instruction cycle involves: 1. \*\*Fetch:\*\* Load the instruction from the memory address pointed to by the PC into the IR. Increment the PC. (PC -> MAR, Read, Memory -> MDR, MDR -> IR, PC + 1 -> PC). 2. \*\*Decode:\*\* The Control Unit interprets the instruction in the IR to determine the operation to be performed and the operands involved. 3. \*\*Execute:\*\* The ALU performs the specified operation using the identified operands (fetching operands from memory or registers if needed). 4. \*\*Write Back (Optional):\*\* Store the result back into a register or memory.7. \*\*Q:\*\* Name the registers which are connected to both external and internal bus? What are the signals associated with these registers? (June 2022 Q1) \*\*A:\*\* MAR (Memory Address Register) and MDR (Memory Data Register) are typically connected to both internal CPU buses and the external system bus (specifically, the Address Bus and Data Bus respectively). \* \*\*MAR:\*\* Associated signals: \`MAR\_in\` (load from internal bus), \`MAR\_out\` (drive external Address Bus). \* \*\*MDR:\*\* Associated signals: \`MDR\_in\` (load from internal bus), \`MDR\_out\` (drive internal bus), \`MDR\_in\_external\` (load from external Data Bus), \`MDR\_out\_external\` (drive external Data Bus), Read/Write control signals.8. \*\*Q:\*\* Differentiate between big endian and little endian byte ordering. (July 2021 Q12b) \*\*A:\*\* Endianness refers to the order in which bytes of a multi-byte word are stored in memory. \* \*\*Big Endian:\*\* Stores the most significant byte (MSB) at the lowest memory address. Example: The word \`0x12345678\` stored at address 1000 would have \`12\` at 1000, \`34\` at 1001, \`56\` at 1002, \`78\` at 1003. \* \*\*Little Endian:\*\* Stores the least significant byte (LSB) at the lowest memory address. Example: The word \`0x12345678\` stored at address 1000 would have \`78\` at 1000, \`56\` at 1001, \`34\` at 1002, \`12\` at 1003.9. \*\*Q:\*\* What are condition codes? List the different condition codes. (June 2023 Reg Q12b) \*\*A:\*\* Condition codes (or flags) are status bits stored in a processor status register (PSR) that indicate the outcome of recent ALU operations. They are used for conditional branching. Common condition codes are: \* \*\*N (Negative):\*\* Set if the result is negative (MSB is 1). \* \*\*Z (Zero):\*\* Set if the result is zero. \* \*\*V (Overflow):\*\* Set if arithmetic overflow occurred (result too large for representation). \* \*\*C (Carry):\*\* Set if a carry-out occurred from the MSB (for unsigned arithmetic or shifts).\*\*Essay/Longer Questions (Typically 7-14 Marks)\*\*10. \*\*Q:\*\* With a neat diagram, explain the basic operational concepts in transferring data between the processor and the main memory. (June 2023 Sup Q11a - 7 Marks) \*\*A:\*\* Data transfer involves CPU registers MAR and MDR, and the system bus (Address, Data, Control lines). \* \*\*Diagram:\*\* Show CPU with MAR, MDR, PC, IR, GPRs, Control Unit connected via internal bus. Show System Bus (Address, Data, Control) connecting CPU to Main Memory. \* \*\*Memory Read:\*\* 1. Processor loads the desired address into MAR. (\`Address -> MAR\`) 2. Processor activates the Read signal on the Control Bus. (\`Read = 1\`) 3. MAR places the address onto the Address Bus. 4. Memory decodes the address, fetches the data, and places it on the Data Bus. 5. Memory asserts the MFC (Memory Function Completed) signal. 6. Processor reads data from Data Bus into MDR. (\`Data Bus -> MDR\`) 7. Processor transfers data from MDR to destination (e.g., GPR). (\`MDR -> GPR\`) \* \*\*Memory Write:\*\* 1. Processor loads the desired address into MAR. (\`Address -> MAR\`) 2. Processor loads the data to be written into MDR. (\`Data -> MDR\`) 3. Processor activates the Write signal on the Control Bus. (\`Write = 1\`) 4. MAR places the address onto the Address Bus. 5. MDR places the data onto the Data Bus. 6. Memory decodes the address and stores the data from the Data Bus into the specified location. 7. Memory asserts the MFC signal. 8. Processor drops Write signal.11. \*\*Q:\*\* What are addressing modes? Explain the different types of addressing modes with examples. (June 2023 Sup Q11b - 7 Marks, June 2023 Reg Q11a - 10 Marks, July 2021 Q11a - 4 Marks) \*\*A:\*\* Addressing modes specify how the effective address (EA) of an operand is calculated. Different modes provide flexibility and efficiency. \* \*\*Definition:\*\* The way an instruction specifies the location of its operand(s). \* \*\*Types:\*\* 1. \*\*Immediate:\*\* Operand is part of the instruction itself. EA = Not applicable. Ex: \`MOV R1, #100\` (R1 <- 100). 2. \*\*Register:\*\* Operand is in a CPU register. EA = Register address (implicit). Ex: \`MOV R1, R2\` (R1 <- \[R2\]). 3. \*\*Direct (Absolute):\*\* Instruction contains the memory address of the operand. EA = Address field in instruction. Ex: \`MOV R1, 2000\` (R1 <- Mem\[2000\]). 4. \*\*Register Indirect:\*\* Instruction specifies a register containing the memory address of the operand. EA = \[Register\]. Ex: \`MOV R1, \[R2\]\` (R1 <- Mem\[\[R2\]\]). 5. \*\*Indexed:\*\* EA = \[Register\] + Offset (Offset is in the instruction). Ex: \`MOV R1, 10\[R2\]\` (R1 <- Mem\[\[R2\]+10\]). Useful for arrays. 6. \*\*Relative:\*\* EA = \[PC\] + Offset. Used for branching relative to the current instruction. Ex: \`BEQ Label\` (Branch if Zero to Label, EA = PC + displacement to Label). 7. \*\*Auto-increment:\*\* EA = \[Register\], then Register <- \[Register\] + operand\_size. Ex: \`MOV R1, (R2)+\`. 8. \*\*Auto-decrement:\*\* Register <- \[Register\] - operand\_size, then EA = \[Register\]. Ex: \`MOV R1, -(R2)\`. \*(Provide brief explanation and example for each mode listed)\*. \*(For July 2021 Q11a, focus on how Arrays (Indexed), Pointers (Register Indirect), Constants (Immediate), Variables (Direct/Indexed) map to these modes).\*12. \*\*Q:\*\* Draw the diagram of a single-bus organization of the datapath inside a processor. Give the control sequence for executing the instruction Add \[R1\], R2 ie, \[R1\]←\[R1\]+R2 in a single-bus organization. (June 2023 Sup Q12a - 10 Marks) / Draw the diagram of single bus organization, write the control sequence for the instruction ADD \[R2\],R3 for the above mentioned single bus organization. (June 2022 Q12b - 8 Marks) \*\*A:\*\* \* \*\*Diagram:\*\* Draw a standard single-bus datapath. Include: \* Internal Processor Bus. \* Registers (PC, IR, MAR, MDR, GPRs like R0, R1, R2, R3..., Y, Z). \* ALU with inputs A and B. \* Multiplexer (MUX) selecting constant values (e.g., 4 for PC increment). \* Control Unit (shown as a block generating signals). \* Connections: All components connected to the single bus. ALU input A connected to bus, input B connected to register Y. ALU output connected to register Z. Registers have \`\_in\` and \`\_out\` control signals. \* \*\*Control Sequence for \`Add \[R1\], R2\` (\[R1\] <- \[R1\] + R2):\*\* (Assumes R1 holds the address, R2 holds data to add) 1. \`R1\_out\`, \`MAR\_in\`: Transfer address from R1 to MAR. 2. \`Read\`, \`MDR\_inE\`, \`WMFC\`: Initiate memory read, wait for memory, load data into MDR. 3. \`MDR\_out\`, \`Y\_in\`: Move the fetched operand (from Mem\[R1\]) into register Y (ALU input B). 4. \`R2\_out\`, \`ALU\_Add\`, \`Z\_in\`: Move R2 content onto bus (ALU input A), perform addition (A+B), store result in Z. 5. \`Z\_out\`, \`MDR\_in\`: Move result from Z to MDR. 6. \`R1\_out\`, \`MAR\_in\`: Put address back into MAR (needed for write). 7. \`Write\`, \`MDR\_outE\`, \`WMFC\`: Initiate memory write of MDR content to address in MAR, wait for completion. 8. \`End\`: Instruction complete. \* \*\*Control Sequence for \`ADD \[R2\], R3\` (\[R2\] <- \[R2\] + R3):\*\* (Assumes R2 holds data, R3 holds data) 1. \`R2\_out\`, \`Y\_in\`: Move content of R2 to register Y (ALU input B). 2. \`R3\_out\`, \`ALU\_Add\`, \`Z\_in\`: Move R3 content onto bus (ALU input A), perform addition, store result in Z. 3. \`Z\_out\`, \`R2\_in\`, \`End\`: Move result from Z back into R2. Instruction complete. \*(Note: The interpretation of \`Add \[R1\], R2\` varies. The first sequence assumes \[R1\] is the \*value\* at the address in R1. The second interpretation assumes R1 is the destination register, and the first operand is fetched \*from memory\* using an addressing mode, while R2 is a register operand. The provided solution assumes the first interpretation based on the format "\[R1\]<-\[R1\]+R2". June 2022 Q12b ADD \[R2\], R3 is likely register-to-register ADD R3,R2 storing in R2 based on typical assembly, but the \[R2\] notation is ambiguous; could mean memory operand at address R2 added to R3, result in R3. The second provided sequence assumes register-to-register.)\*13. \*\*Q:\*\* Draw the diagram of a multi-bus organization with 3 buses, write the control sequence for the instruction ADD \[R1\],R2,R3 for the above mentioned multi-bus organization. (June 2023 Reg Q12a - 9 Marks) \*\*A:\*\* \* \*\*Diagram:\*\* Draw a 3-bus (e.g., A, B, C or Source1, Source2, Destination) organization. \* Show GPRs connected to provide operands to Bus A and Bus B simultaneously. \* Show ALU taking inputs from Bus A and Bus B. \* Show ALU output connected to Bus C. \* Show Bus C connected back to write into GPRs. \* Include MAR, MDR, PC, IR connected appropriately (may use specific buses or direct paths). \* \*\*Control Sequence for \`ADD \[R1\], R2, R3\` (R3 <- Mem\[\[R1\]\] + \[R2\]):\*\* (Assumes R1 holds address, R2 holds data, R3 is destination) 1. \`R1\_outA\`, \`MAR\_in\`: Transfer address from R1 via Bus A to MAR. 2. \`Read\`, \`MDR\_inE\`, \`WMFC\`: Initiate read, wait, load data into MDR. 3. \`MDR\_outA\`, \`R2\_outB\`, \`ALU\_Add\`, \`R3\_in\`, \`End\`: Transfer memory data from MDR via Bus A to ALU input A, Transfer R2 data via Bus B to ALU input B, perform addition, Transfer result via Bus C directly into R3. (This step shows the parallelism advantage).14. \*\*Q:\*\* Illustrate the single bus organization of processor unit with the help of suitable diagrams. Explain, listing the control signals, how the following operations are handled in this organization. i) Transfer contents of register R5 to R1 ii) Move (R6), R2 (Fetch a word from memory and move it to register R2, when the memory address is stored in register R6). (July 2021 Q11b - 10 Marks) \*\*A:\*\* \* \*\*Diagram:\*\* (Same as Q12a diagram). \* \*\*i) Transfer R5 to R1 (R1 <- \[R5\]):\*\* 1. \`R5\_out\`, \`R1\_in\`, \`End\`: Enable output of R5 onto the bus, Enable input of R1 from the bus. \* \*\*ii) Move (R6), R2 (R2 <- Mem\[\[R6\]\]):\*\* 1. \`R6\_out\`, \`MAR\_in\`: Put address from R6 into MAR. 2. \`Read\`, \`MDR\_inE\`, \`WMFC\`: Initiate memory read from address in MAR, wait, load data into MDR. 3. \`MDR\_out\`, \`R2\_in\`, \`End\`: Move data from MDR onto the bus and into R2.15. \*\*Q:\*\* Compare and contrast single bus and multi-bus organization of CPU? (June 2022 Q11a - 4 Marks) \*\*A:\*\* \* \*\*Single Bus:\*\* \* Structure: All components share a single internal bus. \* Pros: Simpler design, lower cost. \* Cons: Slower execution (only one transfer per clock cycle - bottleneck), requires more steps/clock cycles per instruction. \* \*\*Multi-Bus:\*\* \* Structure: Multiple internal buses (e.g., 2 or 3) allow simultaneous data transfers. \* Pros: Faster execution (parallel transfers possible, e.g., fetch two operands simultaneously), fewer steps/clock cycles per instruction. \* Cons: More complex design, higher cost, more complex control unit.---\*\*Module 2: Register Transfer Logic, Processor Logic Design\*\*\*\*(Syllabus Topics:\*\* RTL (inter-register transfer, arithmetic/logic/shift micro-ops), Processor org, ALU, Arithmetic/Logic circuit design, Status register, Shifter design, Accumulator design.)\*\*Short Answer Questions (Typically 3 Marks)\*\*1. \*\*Q:\*\* What are the basic components of Register-Transfer Logic (RTL) method? (June 2023 Sup Q3) \*\*A:\*\* The basic components described using RTL are: \* \*\*Registers:\*\* Store information (e.g., R1, MAR, PC). \* \*\*Micro-operations:\*\* Elementary operations performed on data in registers (e.g., transfer, add, shift, clear). \* \*\*Control Functions:\*\* Boolean functions determining when micro-operations execute (e.g., T1: R1 <- R0). \* \*\*Buses:\*\* Pathways for transferring data between registers.2. \*\*Q:\*\* Draw the hardware implementation of a 4-bit combinational shifter. (June 2023 Sup Q4) \*\*A:\*\* A 4-bit combinational shifter can be implemented using 4-to-1 multiplexers (MUXes). For each bit position (0 to 3), a MUX selects the output based on control signals (e.g., S1, S0). \* Inputs to each MUX\[i\]: Bit\[i\] (no shift), Bit\[i-1\] (right shift input), Bit\[i+1\] (left shift input), Serial Input / 0 (for logical shifts). \* Control Signals (S1, S0) select the operation: e.g., 00=No Shift, 01=Shift Right, 10=Shift Left, 11=Load/Clear. \*(A diagram showing four 4-to-1 MUXes with appropriate inputs and control lines is needed).\*3. \*\*Q:\*\* What is micro-operation? With help of examples explain shift micro-operation. (June 2023 Reg Q3) \*\*A:\*\* A micro-operation is an elementary operation performed on data stored in registers or memory during one clock pulse. \* \*\*Shift Micro-operations:\*\* Used for serial data transfer or arithmetic/logical manipulation. Examples: \* \`shl R1\` (Logical Shift Left R1): Shifts bits left, MSB lost, LSB filled with 0. (RTL: \`R1 <- shl R1\`) \* \`shr R1\` (Logical Shift Right R1): Shifts bits right, LSB lost, MSB filled with 0. (RTL: \`R1 <- shr R1\`) \* \`ashr R1\` (Arithmetic Shift Right R1): Shifts bits right, LSB lost, MSB retains original sign bit. (RTL: \`R1 <- ashr R1\`) \* \`cil R1\` (Circular Shift Left R1): Shifts bits left, MSB wraps around to LSB. (RTL: \`R1 <- cil R1\`)4. \*\*Q:\*\* How is the two port memory organization of processor unit better when compared to scratch pad memory organization? (July 2021 Q3) \*\*A:\*\* \* \*\*Scratchpad:\*\* A small, fast internal SRAM usable like registers but accessed via memory addresses. Typically single-ported (one read or one write at a time). \* \*\*Two-Port Memory:\*\* Allows two simultaneous accesses (e.g., two reads, or one read and one write) in the same clock cycle. This enhances parallelism, especially for fetching two operands for the ALU simultaneously, potentially speeding up execution compared to a single-ported scratchpad where two fetches would take two cycles.5. \*\*Q:\*\* Write a short note about accumulator register? (June 2023 Reg Q13b - 5 Marks, but fits as short note concept) \*\*A:\*\* An accumulator is a special CPU register used in many early or simpler processor designs. It serves as an implicit source operand and the default destination for most Arithmetic Logic Unit (ALU) operations. For example, an \`ADD X\` instruction would typically mean \`AC <- AC + Mem\[X\]\`. This simplifies instruction formats (one-address instructions) but limits parallelism as most operations involve the accumulator.\*\*Essay/Longer Questions (Typically 7-14 Marks)\*\*6. \*\*Q:\*\* Show the hardware implementation of the following conditional control statements T1: C ← A, T2: C ← B, where A, B, C are registers. (June 2023 Sup Q13a - 7 Marks) / Give the block diagram of circuit that implements following statements in register transfer logic: T1; C←A, T5: C←B (July 2021 Q4 - 3 Marks) \*\*A:\*\* \* \*\*Hardware:\*\* Use a 2-to-1 Multiplexer (MUX) whose output feeds the input of register C. \* \*\*Inputs:\*\* Register A output connects to MUX input 0. Register B output connects to MUX input 1. \* \*\*Select Line:\*\* The select line of the MUX is controlled by the timing signals (T1, T2/T5). Assuming T1 and T2/T5 are mutually exclusive: \`Select = T2\` (or T5). If T2/T5 is active (1), B is selected. If T2/T5 is inactive (0) and T1 is active, A is selected (Requires logic: \`Select = T2/T5\`). A simpler way is to control the Load signal of register C. \* \*\*Load Control:\*\* The Load Enable signal for register C is activated only when the transfer should happen. \`Load\_C = T1 + T2\` (or T1 + T5). \* \*\*Alternative using Bus:\*\* If using a bus: \* \`T1: A\_out, C\_in\` \* \`T2 (or T5): B\_out, C\_in\` \* \*\*Circuit Diagram:\*\* Show registers A, B, C. Connect outputs of A and B to inputs of a 2x1 MUX. Connect MUX output to input of C. Show control signals T1 and T2/T5 controlling the MUX select and/or the Load signal of C based on the chosen implementation.7. \*\*Q:\*\* What is a scratchpad memory? Draw the block diagram of a processor employing scratchpad memory. (June 2023 Sup Q13b - 7 Marks) \*\*A:\*\* \* \*\*Definition:\*\* Scratchpad memory is a small, high-speed internal memory (SRAM) integrated within the CPU or on the same chip. It's addressed like memory but has speed comparable to registers. Used for temporary storage of frequently accessed data or intermediate results to avoid slower main memory access. \* \*\*Block Diagram:\*\* Show the CPU core (ALU, Control Unit, Registers like PC, IR). Show the internal Scratchpad Memory block connected to the CPU's internal address and data buses, distinct from the main memory interface (which uses MAR, MDR, external buses). Show control signals for accessing the scratchpad.8. \*\*Q:\*\* Design an adder/subtractor circuit with one selection variable s and two inputs A and B. When s = 0, the circuit performs F = A+B. When s = 1, the circuit performs F = A – B. (June 2023 Sup Q14a - 7 Marks) / Design an adder circuit with one selection variable S and 2 inputs A and B. When S=0 circuit performs A+B, when S=1 it performs A-B by taking twos complement of B? (June 2023 Reg Q13a - 9 Marks) \*\*A:\*\* To perform A - B using an adder, calculate A + (2's complement of B). 2's complement of B = (1's complement of B) + 1. \* \*\*Circuit:\*\* Use an N-bit full adder (where N is the number of bits for A and B). \* Input A goes directly to the A inputs of the full adder. \* Input B goes through N XOR gates. The other input to each XOR gate is the selection variable 's'. \* If s=0, B XOR 0 = B. \* If s=1, B XOR 1 = B' (1's complement of B). \* The selection variable 's' is also connected to the Carry-in (Cin) of the least significant bit's full adder. \* \*\*Operation:\*\* \* When s=0: XOR outputs B. Cin=0. Adder performs F = A + B + 0 = A + B. \* When s=1: XOR outputs B'. Cin=1. Adder performs F = A + B' + 1 = A + (2's complement of B) = A - B. \* \*\*Diagram:\*\* Draw an N-bit full adder block. Show inputs A connected directly. Show inputs B going through XOR gates controlled by 's'. Show 's' connected to Cin. Show the N-bit output F and the final Carry-out (Cout).9. \*\*Q:\*\* Give the hardware design for generating status bits for an 8-bit ALU. (June 2023 Sup Q14b - 7 Marks) / Give a simple design for generating status bits for an 8-bit ALU? (June 2023 Reg Q14a - 6 Marks) / Explain with the help of a block diagram the design of a 4 bit status register for an 8 bit ALU. The four status bits are C (carry), S(sign), Z(zero) and V (overflow). Clearly indicate the purpose of each status bit and how they are set or reset. (July 2021 Q13b - 7 Marks) \*\*A:\*\* A status register holds flags reflecting the result (F\[7..0\]) of an 8-bit ALU operation involving inputs A\[7..0\] and B\[7..0\]. \* \*\*Diagram:\*\* Show the 8-bit ALU, its inputs A and B, its 8-bit output F, and Carry-out (Cout/C8). Show logic gates connected to F, A, B, Cout to generate the status bits (C, S, Z, V), which are then loaded into a Status Register. \* \*\*Status Bits Generation:\*\* \* \*\*C (Carry):\*\* Directly connected to the Carry-out (Cout or C8) from the most significant bit adder stage of the ALU. C = Cout. Purpose: Indicates unsigned overflow or used in multi-precision arithmetic. \* \*\*S (Sign/Negative):\*\* Connected to the most significant bit (MSB) of the result F. S = F\[7\]. Purpose: Indicates if the signed result is negative. \* \*\*Z (Zero):\*\* Generated by NORing all bits of the result F. Z = NOR(F\[7\], F\[6\], ..., F\[0\]). Z=1 if all result bits are 0, else Z=0. Purpose: Indicates if the result is zero. \* \*\*V (Overflow):\*\* Detects signed arithmetic overflow. Logic: V = (A\[7\] AND B\[7\] AND NOT F\[7\]) OR (NOT A\[7\] AND NOT B\[7\] AND F\[7\]) for addition. Alternatively, V = C8 XOR C7 (Carry into MSB vs Carry out of MSB). Purpose: Indicates if signed result is too large to fit.10. \*\*Q:\*\* Illustrate and explain the organization of a processor unit where processor registers and ALU are connected through common buses. Explain how the micro operation R2 ← R3+R4 would be performed using this organization, where R2, R3 and R4 are processor registers. (July 2021 Q13a - 7 Marks) \*\*A:\*\* This describes a bus-based internal CPU organization. \* \*\*Diagram:\*\* Show multiple GPRs (R0, R1, R2, R3, R4...), ALU, and possibly temporary registers (like Y, Z in single-bus) connected via one or more internal buses (e.g., a single bus, or A, B, C buses). Show control signals (\`Rx\_out\`, \`Rx\_in\`, \`ALU\_op\`, \`Y\_in\`, \`Z\_in\` etc.). \* \*\*Micro-operation R2 ← R3+R4 (Single Bus):\*\* 1. \`R3\_out\`, \`Y\_in\`: Move content of R3 into temporary register Y (connects to ALU input B). 2. \`R4\_out\`, \`ALU\_Add\`, \`Z\_in\`: Place R4 onto bus (connects to ALU input A), perform addition, store result in temporary register Z. 3. \`Z\_out\`, \`R2\_in\`, \`End\`: Move result from Z onto the bus and into R2. \* \*\*Micro-operation R2 ← R3+R4 (Multi-Bus, e.g., 3-bus A,B,C):\*\* 1. \`R3\_outA\`, \`R4\_outB\`, \`ALU\_Add\`, \`R2\_in\`, \`End\`: Simultaneously output R3 to Bus A (ALU input A) and R4 to Bus B (ALU input B), perform addition, route result via Bus C directly into R2. (Fewer steps due to parallelism).11. \*\*Q:\*\* Design and draw a combinational logic shifter using multiplexers with two selection variables, H1 and H0. The operations of shifter should be as specified in the following table: H1H0=00: S←0 (Transfer 0s), H1H0=01: S←shl F, H1H0=10: S←shr F, H1H0=11: S←F (No shift). (July 2021 Q14a - 10 Marks) / Design 4-bit combinational logic shifter which will perform the operation given below with 2 control variable H1&H0? i) Shrl ii) clear iii) Load all bits with 1 (June 2022 Q14b - 6 Marks - Different ops specified) \*\*A:\*\* (Focus on July 2021 Q14a first) \* \*\*Design:\*\* Use 4-bit input F\[3..0\] and 4-bit output S\[3..0\]. Requires four 4-to-1 MUXes (one for each output bit S\[i\]). Control signals H1, H0 select the operation. \* \*\*MUX Inputs (for S\[i\]):\*\* \* Input 0 (H1H0=00): Connect to logic '0'. (Implements S←0). \* Input 1 (H1H0=01): Connect to F\[i-1\] (for i>0) and Serial\_In\_Left (for i=0). (Implements Shift Left). Serial\_In\_Left is typically '0' for logical shift. \* Input 2 (H1H0=10): Connect to F\[i+1\] (for i<3) and Serial\_In\_Right (for i=3). (Implements Shift Right). Serial\_In\_Right is typically '0' for logical shift. \* Input 3 (H1H0=11): Connect to F\[i\]. (Implements No Shift S←F). \* \*\*Diagram:\*\* Draw the four 4-to-1 MUXes. Label inputs F\[3..0\]. Label outputs S\[3..0\]. Show connections to MUX inputs based on the logic above. Show H1, H0 connected to the select lines of all MUXes. Show Serial\_In\_Left and Serial\_In\_Right connections (or connect to '0'). \*(For June 2022 Q14b, the MUX inputs would change based on the required operations: Shrl -> F\[i+1\]; Clear -> '0'; Load 1s -> '1'. A fourth operation would be needed or assumed, like No Shift).\*---\*\*Module 3: Arithmetic Algorithms, Pipelining\*\*\*\*(Syllabus Topics:\*\* Multiplication (Binary, Array, Booth's), Division (Restoring), Pipelining (Principles, Classification, Instruction/Arithmetic, Hazards).)\*\*Short Answer Questions (Typically 3 Marks)\*\*1. \*\*Q:\*\* Design 3 X 2 array multiplier. (June 2023 Sup Q5, June 2022 Q5) \*\*A:\*\* Multiplies a 3-bit multiplicand (X2 X1 X0) by a 2-bit multiplier (Y1 Y0). Result is 5 bits (P4 P3 P2 P1 P0). \* \*\*Structure:\*\* Uses AND gates to generate partial products and Full Adders (or Half Adders) to sum them. \* \*\*Partial Products:\*\* \* Row 0: (X2 AND Y0), (X1 AND Y0), (X0 AND Y0) \* Row 1: (X2 AND Y1), (X1 AND Y1), (X0 AND Y1) (Shifted one position left) \* \*\*Summation:\*\* \* P0 = (X0 AND Y0) \* P1 = (X1 AND Y0) + (X0 AND Y1) (Requires 1 HA/FA) \* P2 = (X2 AND Y0) + (X1 AND Y1) + Carry\_from\_P1 (Requires 1 FA) \* P3 = (X2 AND Y1) + Carry\_from\_P2 (Requires 1 HA/FA) \* P4 = Carry\_from\_P3 \* \*\*Diagram:\*\* Draw the grid of AND gates and the arrangement of adders summing the partial products diagonally.2. \*\*Q:\*\* Explain the logic used behind booth multiplication algorithm. (June 2023 Sup Q6, June 2022 Q4) \*\*A:\*\* Booth's algorithm speeds up multiplication, especially for signed numbers (2's complement), by handling strings of 1s efficiently. It examines multiplier bits in pairs (current bit \`Qi\` and previous bit \`Q(i-1)\`). \* \*\*Logic:\*\* \* \`00\` or \`11\`: String of 0s or middle of string of 1s -> Arithmetic Shift Right only. \* \`01\`: End of a string of 1s -> Add Multiplicand, then Arithmetic Shift Right. (Equivalent to +1 \* 2^i) \* \`10\`: Beginning of a string of 1s -> Subtract Multiplicand (Add 2's complement), then Arithmetic Shift Right. (Equivalent to -1 \* 2^i) \* Reduces the number of additions/subtractions compared to standard multiplication if there are strings of 1s or isolated 1s.3. \*\*Q:\*\* Check the correctness of the following statements and justify your results: i)All unifunctional pipeline are static. But all static pipeline are not unifunctional. ii)All dynamic pipelines are multifunctional. But all multifunctional pipeline are not dynamic because different time. (June 2023 Reg Q4) \*\*A:\*\* \* \*\*i) Correct.\*\* A unifunctional pipeline performs only one type of operation (e.g., FP addition). Since the function is fixed, the pipeline configuration is fixed, making it static. However, a static pipeline (fixed configuration) could potentially be designed to handle multiple functions using different data paths within that fixed structure, just not reconfigurable ones (hence not all static are unifunctional, although typically they are). \* \*\*ii) Correct.\*\* A dynamic pipeline can be reconfigured to perform variable functions at different times, meaning it must be multifunctional. However, a multifunctional pipeline (capable of different functions) might have a fixed configuration (static) and select the function using control signals, rather than being dynamically reconfigurable. Time taken for different functions can vary even in static multifunctional pipelines.4. \*\*Q:\*\* Divide (1000)2 by (11)2 using restoring division method. (June 2023 Reg Q5) \*\*A:\*\* Dividend A = 1000 (8), Divisor B = 11 (3). Use registers Q (Dividend), M (Divisor), A (Accumulator, initially 0). n=4 bits for Q. M=0011, -M (2's comp) = 1101. 1. Initialize: A=0000, Q=1000, M=0011, n=4. 2. Shift Left AQ: A=0001, Q=000?. 3. A = A - M: A = 0001 + 1101 = 1110. A is negative (MSB=1). 4. Restore A, set Q0=0: A=0001, Q=0000. (n=3) 5. Shift Left AQ: A=0010, Q=000?. 6. A = A - M: A = 0010 + 1101 = 1111. A is negative. 7. Restore A, set Q0=0: A=0010, Q=0000. (n=2) 8. Shift Left AQ: A=0100, Q=000?. 9. A = A - M: A = 0100 + 1101 = 0001. A is positive (MSB=0). 10. Set Q0=1: A=0001, Q=0001. (n=1) 11. Shift Left AQ: A=0010, Q=001?. 12. A = A - M: A = 0010 + 1101 = 1111. A is negative. 13. Restore A, set Q0=0: A=0010, Q=0010. (n=0) Result: Quotient Q = 0010 (2), Remainder A = 0010 (2). (8 / 3 = 2 remainder 2).5. \*\*Q:\*\* With proper example describe about arithmetic pipelining? (June 2023 Reg Q6) \*\*A:\*\* Arithmetic pipelining applies pipeline techniques to speed up complex arithmetic operations by breaking them into stages. Example: Floating-point addition. \* Stages: 1. Compare Exponents: Subtract exponents to find the difference. 2. Align Mantissas (Shift): Shift the mantissa of the smaller number right by the exponent difference. 3. Add Mantissas: Perform addition on the aligned mantissas. 4. Normalize Result: Shift the resulting mantissa and adjust the exponent to fit the normalized format (e.g., 1.xxxxx \* 2^exp). \* Operation: Each stage operates concurrently on different sets of operands. While one pair of numbers is having mantissas added (Stage 3), the next pair can be undergoing exponent comparison (Stage 1). This increases throughput.6. \*\*Q:\*\* Draw the flow chart for Booth's Multiplication Algorithm. (July 2021 Q5) \*\*A:\*\* \*\*Flowchart:\*\* \* Start \* Initialize: Accumulator A = 0, Q-1 = 0 (extra bit), M = Multiplicand, Q = Multiplier, Count = n (number of bits). \* Loop (while Count > 0): \* Examine Q0 and Q-1: \* If (Q0, Q-1) == (1, 0): A = A - M (A = A + 2's comp of M) -> Go to Shift \* If (Q0, Q-1) == (0, 1): A = A + M -> Go to Shift \* If (Q0, Q-1) == (0, 0) or (1, 1): -> Go to Shift \* Shift: Perform Arithmetic Shift Right on A, Q, Q-1 (A -> A, A\[0\] -> Q\[n-1\], ..., Q\[0\] -> Q-1). \* Decrement Count: Count = Count - 1. \* End Loop \* Result is in A and Q. \* End7. \*\*Q:\*\* Illustrate Read After Write (RAW) hazard with an example. (July 2021 Q6) \*\*A:\*\* A RAW hazard occurs when an instruction tries to read an operand before a preceding instruction has finished writing to it. \* \*\*Example:\*\* \`\`\` I1: ADD R1, R2, R3 ; R1 <- R2 + R3 I2: SUB R4, R1, R5 ; R4 <- R1 - R5 \`\`\` \* \*\*Hazard:\*\* Instruction I2 needs the value of R1, which is calculated by I1. In a pipeline, I2 might reach the operand fetch stage before I1 has completed the execute/write-back stage. If I2 reads the old value of R1, the result will be incorrect. \* \*\*Resolution:\*\* Requires stalling I2 or using data forwarding/bypassing to provide the result from I1's ALU output directly to I2's ALU input.8. \*\*Q:\*\* Discuss about pipeline hazards? (June 2022 Q6) \*\*A:\*\* Pipeline hazards are situations that prevent the next instruction in the instruction stream from executing during its designated clock cycle. They reduce the ideal speedup achievable by pipelining. Types: \* \*\*Structural Hazards:\*\* Hardware resources are insufficient; two instructions require the same resource at the same time (e.g., accessing memory). Solved by duplicating resources. \* \*\*Data Hazards:\*\* An instruction depends on the result of a previous instruction still in the pipeline. Types: RAW (Read After Write), WAR (Write After Read), WAW (Write After Write). Solved by forwarding/bypassing or pipeline stalls (bubbles). \* \*\*Control Hazards (Branch Hazards):\*\* Occur due to branch instructions; the pipeline fetches the next sequential instruction before the branch outcome (taken/not taken) is known. Solved by branch prediction, delayed branching, or flushing the pipeline.\*\*Essay/Longer Questions (Typically 7-14 Marks)\*\*9. \*\*Q:\*\* Draw the hardware arrangement for restoring integer division. Show how the division of 1000 by 11 is performed by restoring integer division.\* (June 2023 Sup Q15a - 10 Marks) \*\*A:\*\* \* \*\*Hardware Arrangement:\*\* \* Register M: Holds Divisor. \* Register Q: Holds Dividend (shifts left, quotient bits enter LSB). \* Register A: Accumulator (initially 0, holds partial remainder, shifts left with Q). \* N-bit Adder/Subtractor: Performs A = A - M. \* Control Logic: Generates shift, subtract, restore, set Q0 signals based on A's sign bit and counter. \* Counter: Tracks number of steps (n). \* Diagram: Show registers A and Q combined as a shift register. Show M. Show Adder/Subtractor taking input from A and M (or -M). Show control logic monitoring A\[MSB\] and counter. \* \*\*Example: 1000 / 11 (Binary: 1000 / 0011):\*\* (Detailed steps as in Q4 above). 1. Init: A=0000, Q=1000, M=0011, n=4. 2. ShL(AQ): A=0001, Q=000?. A=A-M (0001-0011=1110). A<0. Restore A=0001, Q0=0. Q=0000. n=3. 3. ShL(AQ): A=0010, Q=000?. A=A-M (0010-0011=1111). A<0. Restore A=0010, Q0=0. Q=0000. n=2. 4. ShL(AQ): A=0100, Q=000?. A=A-M (0100-0011=0001). A>=0. Q0=1. Q=0001. n=1. 5. ShL(AQ): A=0010, Q=001?. A=A-M (0010-0011=1111). A<0. Restore A=0010, Q0=0. Q=0010. n=0. Result: Quotient Q=0010 (2), Remainder A=0010 (2).10. \*\*Q:\*\* Show how the multiplication of 1101 and 1011 is performed by a sequential circuit multiplier. (June 2023 Sup Q15b - 4 Marks) \*\*A:\*\* Uses registers A (Accumulator, initially 0), Q (Multiplier=1011), M (Multiplicand=1101), Counter n=4. 1. Init: A=0000, Q=1011, M=1101, n=4. Q0=1. 2. Q0=1 => A=A+M: A=0000+1101=1101. ShiftRight(A,Q): A=1110, Q=1101. n=3. Q0=1. 3. Q0=1 => A=A+M: A=1110+1101=11011. ShiftRight(A,Q): A=11101, Q=1110. (Keep 4 bits for A: A=1101). ShiftRight(A,Q): A=1110, Q=1110. n=2. Q0=0. 4. Q0=0 => ShiftRight(A,Q): A=0111, Q=0111. n=1. Q0=1. 5. Q0=1 => A=A+M: A=0111+1101=10100. ShiftRight(A,Q): A=11010, Q=0011. (Keep 4 bits for A: A=1010). ShiftRight(A,Q): A=1101, Q=0011. n=0. Result: In A, Q = 10001111 (Binary for 143). (1101 is 13, 1011 is 11. 13 \* 11 = 143). \*(Note: Check intermediate arithmetic carefully, especially carry handling and A size)\*. A standard algorithm keeps n bits in A. Let's redo: 1. Init: A=0000, Q=1011, M=1101, n=4. Q0=1. 2. A=A+M: A=1101. ShR(AQ): A=0110, Q=1101. n=3. Q0=1. 3. A=A+M: A=0110+1101=10011. ShR(AQ): A=1100, Q=1110. n=2. Q0=0. 4. ShR(AQ): A=0110, Q=0111. n=1. Q0=1. 5. A=A+M: A=0110+1101=10011. ShR(AQ): A=1100, Q=1011. n=0. Result: AQ = 10011011 (Binary for 155). Still incorrect. Need to use n+1 bits for A or handle carry correctly. Let's use A as 5 bits including carry C. C,A initial 0,0000. 1. Init: C=0, A=0000, Q=1011, M=1101, n=4. Q0=1. 2. C,A = A+M: 0,0000 + 1101 = 0,1101. ShR(C,A,Q): C=0, A=0110, Q=1101. n=3. Q0=1. 3. C,A = A+M: 0,0110 + 1101 = 1,0011. ShR(C,A,Q): C=1, A=1001, Q=1110. n=2. Q0=0. 4. ShR(C,A,Q): C=0, A=1100, Q=1110. n=2. Q0=0. (Correction: Previous Q0 was 1, now shifted to Q0=0). 5. ShR(C,A,Q): C=0, A=0110, Q=0111. n=1. Q0=1. 6. C,A = A+M: 0,0110 + 1101 = 1,0011. ShR(C,A,Q): C=1, A=1001, Q=1011. n=0. Result: AQ = 10011011 (Binary 155). Still wrong. 13\*11=143 (10001111). There might be an error in manual calculation or understanding of the simple sequential multiplier steps. Standard result is in AQ.11. \*\*Q:\*\* Explain the classification of pipeline processors. (June 2023 Sup Q16a - 10 Marks) / Explain in detail about pipeline processors? (June 2023 Reg Q15b - 7 Marks) / Explain the various pipeline structures available inside a computer (July 2021 Q15b - 6 Marks) \*\*A:\*\* Pipelining overlaps instruction execution stages to increase throughput. \* \*\*Basic Principle:\*\* Divide instruction processing into sequential stages (e.g., IF, ID, EX, MEM, WB). Process different instructions in different stages simultaneously. \* \*\*Classification:\*\* \* \*\*Instruction Pipeline:\*\* Overlaps stages of the instruction cycle (fetch, decode, execute, etc.). Standard in modern CPUs. \* \*\*Arithmetic Pipeline:\*\* Breaks down complex arithmetic operations (like FP add, multiply) into stages. Used within ALUs/FPUs. \* \*\*Based on Functionality:\*\* \* \*\*Unifunctional:\*\* Can only perform one type of operation (e.g., only FP addition). \* \*\*Multifunctional:\*\* Can perform different functions, either one at a time or sometimes multiple simultaneously using different paths. \* \*\*Based on Configuration:\*\* \* \*\*Static:\*\* The pipeline configuration and function are fixed. Can be unifunctional or multifunctional (selecting function via control). \* \*\*Dynamic:\*\* The pipeline configuration can be changed dynamically, allowing more flexible execution of different function types. Often multifunctional. \* \*\*Based on Level:\*\* Microinstruction level, instruction level, processor level. \* \*\*Structures:\*\* Can be linear (stages in sequence) or non-linear (feed-forward/feedback paths). Number of stages varies. \* \*\*Benefits:\*\* Increased instruction throughput, improved performance. \* \*\*Challenges:\*\* Hazards (Structural, Data, Control), increased latency for a single instruction.12. \*\*Q:\*\* Write a note on data hazard detection resolution. (June 2023 Sup Q16b - 4 Marks) / Describe in detail about instruction hazards and their solution? (June 2023 Reg Q16b - 8 Marks) / Explain the various method available to get rid of data hazards inside the system (July 2021 Q16b - 6 Marks) / Describe in detail about data hazards and resolution techniques? (June 2022 Q15b - 8 Marks) \*\*A:\*\* Data hazards occur when instructions have data dependencies that are violated by the pipeline's overlapped execution. Types: RAW, WAR, WAW. \* \*\*Detection:\*\* Hardware checks register identifiers used by instructions currently in different pipeline stages. \* RAW: Check if Read Register ID (in ID/OF stage) matches Write Register ID (in EX/MEM/WB stages of previous instructions). \* WAR: Check if Write Register ID (in ID/OF) matches Read Register ID (in EX/MEM/WB of previous instructions). Less common with standard in-order pipelines. \* WAW: Check if Write Register ID (in ID/OF) matches Write Register ID (in WB of previous instructions). Less common with standard in-order pipelines. \* \*\*Resolution Techniques:\*\* 1. \*\*Forwarding (Bypassing):\*\* Hardware provides the result from an earlier stage (e.g., ALU output, MDR after load) directly to the input of a later stage that needs it, avoiding the need to wait for write-back. Handles many RAW hazards. Requires extra data paths and control logic. 2. \*\*Pipeline Stall (Bubble Insertion):\*\* If forwarding cannot resolve the hazard (e.g., load-use hazard where data isn't ready even after EX stage), the dependent instruction is stalled (delayed) in the pipeline for one or more cycles by inserting NOPs (bubbles). Control logic detects the hazard and freezes relevant stages. 3. \*\*Instruction Scheduling (Compiler Optimization):\*\* The compiler reorders instructions (where possible without changing program logic) to increase the distance between dependent instructions, reducing the likelihood of stalls.13. \*\*Q:\*\* Multiply following using booth's multiplication algorithm: -7 and -3. (June 2023 Reg Q16a - 6 Marks) / Draw the flowchart of Booth's multiplication algorithm and multiply -5 X -4 using booths algorithm? (June 2022 Q16a - 8 Marks) \*\*A:\*\* (Example: -7 \* -3) \* M = -7 (1001 in 4 bits), -M = +7 (0111). Q = -3 (1101 in 4 bits). n=4. A=0000, Q-1=0. 1. Init: A=0000, Q=1101, Q-1=0, n=4. (Q0,Q-1) = (1,0). A=A-M: A=0000+0111=0111. ASR(A,Q,Q-1): A=0011, Q=1110, Q-1=1. n=3. 2. (Q0,Q-1)=(0,1). A=A+M: A=0011+1001=1100. ASR(A,Q,Q-1): A=1110, Q=0111, Q-1=0. n=2. 3. (Q0,Q-1)=(1,0). A=A-M: A=1110+0111=0101. ASR(A,Q,Q-1): A=0010, Q=1011, Q-1=1. n=1. 4. (Q0,Q-1)=(1,1). ASR(A,Q,Q-1): A=0001, Q=0101, Q-1=1. n=0. Result: AQ = 0001 0101. Incorrect. (-7 \* -3 = +21 = 0 10101 in 6 bits). Requires more bits. Let's use 5 bits (sign + 4). M=-7 (11001), -M=+7 (00111). Q=-3 (11101). n=5. A=00000, Q-1=0. 1. Init: A=00000, Q=11101, Q-1=0, n=5. (1,0). A=A-M: A=00000+00111=00111. ASR: A=00011, Q=11110, Q-1=1. n=4. 2. (0,1). A=A+M: A=00011+11001=11100. ASR: A=11110, Q=01111, Q-1=0. n=3. 3. (1,0). A=A-M: A=11110+00111=00101. ASR: A=00010, Q=10111, Q-1=1. n=2. 4. (1,1). ASR: A=00001, Q=01011, Q-1=1. n=1. 5. (1,1). ASR: A=00000, Q=10101, Q-1=1. n=0. Result: AQ = 00000 10101. Represents +21. Correct. (Flowchart as in Q6 above).---\*\*Module 4: Control Logic Design\*\*\*\*(Syllabus Topics:\*\* Control org (Hardwired vs Microprogrammed), Hardwired control, Microprogram control, Control of processor unit, Microprogram sequencer, Microprogrammed CPU org, Horizontal/Vertical microinstructions.)\*\*Short Answer Questions (Typically 3 Marks)\*\*1. \*\*Q:\*\* Give the advantages and disadvantages of hardwired control over microprogrammed control. (June 2023 Sup Q7) \*\*A:\*\* \* \*\*Hardwired Advantages:\*\* Faster operation speed, potentially smaller chip area for simple instruction sets. \* \*\*Hardwired Disadvantages:\*\* Complex to design and debug, inflexible (difficult to modify or add instructions), expensive to change. \* \*\*Microprogrammed Advantages:\*\* Flexible (easy to change/add instructions by modifying microcode), easier to design and debug complex instruction sets, supports emulation. \* \*\*Microprogrammed Disadvantages:\*\* Slower operation speed (extra level of interpretation), requires control memory (adds cost/area).2. \*\*Q:\*\* What is a control word? With an example, show how a control word can be defined. (June 2023 Sup Q8) \*\*A:\*\* A control word is a binary word where each bit (or group of bits/field) represents a control signal required to execute one or more micro-operations within a single clock cycle. All control words for an instruction sequence are stored in control memory (in microprogrammed control) or generated by logic (in hardwired control). \* \*\*Example:\*\* A 16-bit control word: \`| F1 | F2 | F3 | CD | BR | AD |\` \* F1 (3 bits): ALU operation select (e.g., 001=ADD, 010=SUB) \* F2 (3 bits): Source register for ALU input A (e.g., 010=R2) \* F3 (3 bits): Source register for ALU input B (e.g., 011=R3) \* CD (2 bits): Condition code select for branching (e.g., 01=Zero Flag) \* BR (2 bits): Branch type (e.g., 01=JMP, 10=CALL) \* AD (3 bits): Address field / Destination Register select. A specific control word like \`001 010 011 00 00 100\` might mean: Add R2 and R3, no branch, store result in R4.3. \*\*Q:\*\* Differentiate between vertical and horizontal microinstructions. (June 2023 Sup Q17b, June 2023 Reg Q7, July 2021 Q8, June 2022 Q17b) \*\*A:\*\* \* \*\*Horizontal:\*\* \* Format: Wide format, one bit per control signal (or minimally encoded fields). \* Parallelism: High degree of parallelism possible (multiple signals active per microinstruction). \* Encoding: Little or no encoding. \* Speed: Potentially faster execution (less decoding). \* Control Memory: Requires wider control memory. \* Flexibility: High. \* \*\*Vertical:\*\* \* Format: Narrow format, highly encoded fields. \* Parallelism: Limited parallelism (one or few operations per microinstruction). \* Encoding: Highly encoded fields require decoding logic. \* Speed: Slower execution (decoding needed). \* Control Memory: Requires narrower control memory. \* Flexibility: Lower, resembles machine instructions.4. \*\*Q:\*\* Draw and discuss about PLA control logic? (June 2023 Reg Q8) / Explain PLA based control organization with the help of a diagram (July 2021 Q7) \*\*A:\*\* A Programmable Logic Array (PLA) can implement the combinational logic part of a hardwired control unit. \* \*\*Concept:\*\* The control unit's inputs (opcode, flags, state counter bits) are fed into the PLA's AND plane, which generates product terms (minterms). These product terms are selectively ORed together in the OR plane to produce the specific control signal outputs required for each state/input combination. \* \*\*Diagram:\*\* Show Instruction Register (Opcode), Status Flags, State Counter feeding into the Input Buffer/Inverters of the PLA. Show the AND Plane (programmable connections forming AND gates/product terms). Show the OR Plane (programmable connections forming OR gates/sum terms). Show the outputs connected to Control Signal lines (e.g., PC\_in, MAR\_in, ALU\_Add). \* \*\*Discussion:\*\* Offers a structured way to implement complex logic compared to random logic gates. It's less flexible than microprogramming but more regular than pure hardwired logic. Can be slower than optimized hardwired logic due to programmable structure.5. \*\*Q:\*\* Write a note on micro-program control? (June 2022 Q7) \*\*A:\*\* Microprogram control is a method of control unit design where control signals are generated by executing sequences of "microinstructions" stored in a special memory called "Control Memory" (or Control Store). \* \*\*Operation:\*\* The instruction opcode maps to a starting address in Control Memory. A microprogram sequencer fetches microinstructions sequentially or based on branches within the microcode. Each microinstruction specifies the micro-operations (and control signals) to be performed in one clock cycle. \* \*\*Components:\*\* Control Memory, Microprogram Sequencer (uPC), Control Address Register (CAR), Control Data Register (CDR/MIR). \* \*\*Advantages:\*\* Flexibility, ease of implementing complex instructions, systematic design. \* \*\*Disadvantage:\*\* Slower than hardwired control due to memory access time.\*\*Essay/Longer Questions (Typically 7-14 Marks)\*\*6. \*\*Q:\*\* Give the control sequence for implementing the conditional branch instruction Branch-on-Negative in a single bus processor organization. (June 2023 Sup Q12b - 4 Marks) \*\*A:\*\* Instruction: \`BRN Target\_Address\` (Branch if N flag = 1) 1. Fetch & Decode (already done). CU identifies BRN and extracts Target\_Address offset. 2. \`Status\_Reg\_out\`, Check N flag: Output status register (or just N flag) to control logic. 3. If (N == 1): \`Offset\_out\`, \`ALU\_Add\`, \`Z\_in\`: Put Target\_Address offset from IR onto bus, put PC onto bus (via ALU pass-through or temp reg), add them, store result in Z. 4. If (N == 1): \`Z\_out\`, \`PC\_in\`, \`End\`: Load calculated target address from Z into PC. 5. If (N == 0): \`End\`: Do nothing, PC already points to next sequential instruction. \*(Alternative: If target address is absolute, step 3 loads it directly or via Z into PC)\*.7. \*\*Q:\*\* With a block diagram, explain how control signals are generated using hardwired control. (June 2023 Sup Q17a - 10 Marks, June 2023 Reg Q17a - 8 Marks) \*\*A:\*\* Hardwired control uses combinational logic circuits to generate control signals based on the current instruction, timing state, and status flags. \* \*\*Components:\*\* \* \*\*Instruction Register (IR):\*\* Holds the opcode of the current instruction. \* \*\*Instruction Decoder:\*\* A combinational circuit that decodes the opcode. \* \*\*Timing Generator/State Counter:\*\* Generates timing signals (T0, T1, T2...) or state variables that define steps within an instruction execution. \* \*\*Status Flags:\*\* Inputs from the ALU/Processor Status Register (N, Z, V, C). \* \*\*Control Logic Gates:\*\* AND, OR, NOT gates that combine decoder outputs, timing signals, and status flags according to Boolean expressions defining each control signal. \* \*\*Block Diagram:\*\* Show IR feeding the Decoder. Show State Counter generating timing signals. Show Status Flags. Show Decoder outputs, Timing signals, and Flags as inputs to a "Control Logic" block (represented by gates). Show outputs of Control Logic block as the control signals (e.g., PC\_out, MAR\_in, Read, ALU\_Add, Rx\_in, Rx\_out, End). \* \*\*Operation:\*\* For each control signal, a specific Boolean equation is implemented. Example: \`PC\_out = T0\` (for fetch) \`+ (T2 AND Branch\_Instruction AND Condition\_Met)\` (for branch target calc). The logic activates the required signals at the correct time step based on the instruction and processor state.8. \*\*Q:\*\* List the address-sequencing capabilities of a microprogram sequencer. With a suitable block diagram and function table, explain the organization of a typical microprogram sequencer. (June 2023 Sup Q18 - 14 Marks, July 2021 Q17a - 7 Marks, June 2022 Q17a - 10 Marks) \*\*A:\*\* \* \*\*Address Sequencing Capabilities:\*\* Determine the address of the next microinstruction to be fetched. Capabilities include: 1. \*\*Increment (INC):\*\* Fetch the next sequential microinstruction (CAR <- CAR + 1). Default mode. 2. \*\*Unconditional Branch (JMP):\*\* Load CAR from address field of current microinstruction. 3. \*\*Conditional Branch (BR):\*\* Branch to address field if a specified condition (status flag) is met, otherwise increment. 4. \*\*External Address Mapping:\*\* Map instruction opcode to a starting microinstruction address in control memory. 5. \*\*Subroutine Call (CALL):\*\* Push current CAR+1 onto a subroutine stack (SBR), load CAR from address field. 6. \*\*Subroutine Return (RET):\*\* Pop return address from SBR into CAR. \* \*\*Block Diagram of Microprogram Sequencer:\*\* \* Inputs: Address Field from current Microinstruction Register (MIR/CDR), Condition Code/Flags, Clock, Mapping Logic input (from Opcode). \* Components: Multiplexer (MUX) to select the next address source. Control Address Register (CAR). Subroutine Register/Stack (SBR). Incrementer (+1). Mapping Logic (ROM/PLA). Control Logic based on Branch/Call bits in MIR. \* Outputs: Address to Control Memory (from CAR). \* Connections: Incrementer output, Address Field, Mapping Logic output, SBR output feed into MUX. MUX output feeds CAR. CAR feeds Control Memory Address Bus. Control bits from MIR and Flags control the MUX select lines. \* \*\*Function Table (Example):\*\* Shows how MUX select lines are activated based on Microinstruction bits (e.g., I field for JMP/CALL/RET) and condition flags. | I1 I0 | Condition | MUX Select | Function | Next Address Source | |---|---|---|---|---| | 0 0 | X | 0 | INC | CAR+1 | | 0 1 | 1 | 1 | BR (True) | Address Field | | 0 1 | 0 | 0 | BR (False)| CAR+1 | | 1 0 | X | 2 | CALL | Address Field (Push CAR+1) | | 1 1 | X | 3 | RET | SBR (Pop) | \*(Mapping might use a dedicated input selection)\*---\*\*Module 5: I/O Organization, Memory System\*\*\*\*(Syllabus Topics:\*\* Accessing I/O (Programmed, Interrupt, DMA), Interrupt hardware, DMA, Memory concepts, RAM (Semi-conductor), Memory considerations, ROMs, CAM, Cache (Mapping functions).)\*\*Short Answer Questions (Typically 3 Marks)\*\*1. \*\*Q:\*\* Differentiate between program-controlled I/O and interrupt-driven I/O. (June 2023 Sup Q9) \*\*A:\*\* \* \*\*Program-Controlled I/O (Polling):\*\* The CPU continuously checks the status of the I/O device (polling) to see if it's ready for data transfer. CPU is busy-waiting, wasting cycles if the device is slow. Simple to implement. \* \*\*Interrupt-Driven I/O:\*\* The I/O device signals the CPU via an interrupt request line when it's ready. The CPU suspends its current task, handles the I/O transfer (in an Interrupt Service Routine - ISR), and then resumes the task. More efficient CPU utilization, but more complex hardware/software.2. \*\*Q:\*\* Compare temporal locality of reference and spatial locality of reference. (June 2023 Sup Q10) / Explain the term locality of reference. How is this related to cache memory? (July 2021 Q10) \*\*A:\*\* Locality of reference describes patterns in memory access. Caches exploit this principle. \* \*\*Temporal Locality:\*\* If a memory location is accessed, it's likely to be accessed again soon. (e.g., loops, reused variables). Cache keeps recently accessed items. \* \*\*Spatial Locality:\*\* If a memory location is accessed, nearby memory locations are likely to be accessed soon. (e.g., sequential instruction execution, array traversal). Cache fetches blocks of contiguous memory (cache lines) anticipating nearby accesses. \* \*\*Relation to Cache:\*\* Cache memory works because programs exhibit locality. By storing recently accessed data (temporal) and blocks around it (spatial) in fast cache, most memory references can be satisfied from the cache (cache hit), improving performance.3. \*\*Q:\*\* Why dynamic RAMs need constant refreshing? Give the structure also. (June 2023 Reg Q9) \*\*A:\*\* \* \*\*Need for Refresh:\*\* DRAM stores data as electrical charge on small capacitors within each memory cell. This charge gradually leaks away over time (milliseconds). Refreshing periodically reads the charge and rewrites it to prevent data loss. \* \*\*Structure:\*\* A basic DRAM cell consists of one transistor and one capacitor. The capacitor stores the bit (charged=1, discharged=0). The transistor acts as a switch, controlled by the Word Line, connecting the capacitor to the Bit Line for reading/writing. Cells are arranged in a 2D array with row/column decoders.4. \*\*Q:\*\* Differentiate about memory mapped I/O and I/O mapped I/O? (June 2023 Reg Q10) \*\*A:\*\* Methods for CPU to communicate with I/O devices: \* \*\*Memory-Mapped I/O:\*\* I/O device registers are assigned addresses within the main memory address space. The same instructions used for memory access (e.g., MOV, LOAD, STORE) are used for I/O. Simpler instruction set, but reduces available memory address space. \* \*\*I/O-Mapped I/O (Isolated I/O):\*\* I/O devices have a separate address space. Special I/O instructions (e.g., IN, OUT) are required to access device registers. Full memory address space is available, but requires dedicated I/O instructions.5. \*\*Q:\*\* List and explain the different types of ROMs. (July 2021 Q9, June 2022 Q19b) \*\*A:\*\* ROM (Read-Only Memory) retains data without power. Types vary by programmability: \* \*\*ROM (Masked ROM):\*\* Programmed during manufacturing. Contents cannot be changed. High volume, low cost per unit. \* \*\*PROM (Programmable ROM):\*\* Can be programmed once by the user using special equipment (burns fuses). \* \*\*EPROM (Erasable PROM):\*\* Can be erased using Ultraviolet (UV) light (through a quartz window) and reprogrammed. \* \*\*EEPROM (Electrically Erasable PROM):\*\* Can be erased and reprogrammed electrically, byte-by-byte, while in the circuit. Slower write times than RAM. \* \*\*Flash Memory:\*\* A type of EEPROM that allows block-level erasing and writing. Faster than EEPROM, widely used (SSDs, USB drives).6. \*\*Q:\*\* What are interrupts? List the sequence of steps following an interrupt request? (June 2022 Q9) \*\*A:\*\* An interrupt is a signal from hardware or software indicating an event that needs immediate attention, causing the CPU to suspend its current task and handle the event. \* \*\*Sequence of Steps:\*\* 1. Device raises interrupt request signal. 2. CPU completes the current instruction. 3. CPU acknowledges the interrupt (if enabled and priority allows). 4. CPU pushes the current Program Counter (PC) and Processor Status Word (PSW or flags) onto the system stack (saves context). 5. CPU identifies the interrupting device (using polling or vectored interrupts) and loads the starting address of the corresponding Interrupt Service Routine (ISR) into the PC. 6. CPU executes the ISR to handle the event. 7. ISR finishes, executes a return-from-interrupt instruction. 8. CPU pops the PSW and PC from the stack (restores context). 9. CPU resumes the interrupted program.7. \*\*Q:\*\* Which design feature of SRAM cells helps in value retention without refresh? (June 2022 Q10) \*\*A:\*\* SRAM (Static RAM) cells use a bistable latching circuitry, typically made of 4 to 6 transistors (cross-coupled inverters), to store each bit. As long as power is supplied, the latch maintains its state (0 or 1) indefinitely without needing periodic refreshing like DRAM capacitors.\*\*Essay/Longer Questions (Typically 7-14 Marks)\*\*8. \*\*Q:\*\* Explain how interrupts can be used for coordinating I/O transfers. (June 2023 Sup Q19a - 7 Marks) / Outline the actions taking place in a processor once an interrupt has been raised. (July 2021 Q19b - 7 Marks) / Explain in detail about the mechanisms for accessing I/O devices? (June 2022 Q19a - 9 Marks - Include Interrupts part) \*\*A:\*\* Interrupts provide an efficient way to handle I/O without CPU busy-waiting. \* \*\*Mechanism:\*\* 1. CPU initiates an I/O operation (e.g., tells a disk controller to read data). 2. CPU continues executing other tasks. 3. When the I/O device completes the operation (e.g., data is ready in its buffer), it sends an interrupt signal to the CPU. 4. \*\*CPU Actions upon Interrupt (as detailed in Q6 above):\*\* Finish current instruction, acknowledge interrupt, save PC & PSW, identify source, load ISR address, execute ISR. 5. \*\*ISR Execution:\*\* The ISR performs the necessary actions for the I/O transfer (e.g., reads data from the device buffer into memory, checks for errors, signals completion). 6. \*\*Return:\*\* ISR completes, restores PC & PSW, CPU resumes the interrupted task. \* \*\*Coordination:\*\* This allows the CPU to perform useful work while slow I/O operations are in progress, significantly improving overall system performance compared to programmed I/O. Multiple devices can interrupt, requiring interrupt priority handling and masking mechanisms.9. \*\*Q:\*\* Explain how Direct Memory Access (DMA) technique is used for transferring large blocks of data at high speed. (June 2023 Sup Q19b - 7 Marks) / Outline how Direct Memory Access is implemented? Differentiate between cycle stealing DMA and burst mode DMA. (July 2021 Q20b - 7 Marks) \*\*A:\*\* DMA allows direct transfer of data between I/O devices and main memory without constant CPU intervention, ideal for high-speed, large block transfers. \* \*\*Implementation:\*\* Requires a DMA Controller (DMAC). 1. CPU programs the DMAC: Provides starting memory address, block size (word count), transfer direction (read/write), I/O device address. 2. CPU resumes other tasks. 3. DMAC requests control of the system bus from the CPU (Bus Request signal). 4. CPU grants the bus (Bus Grant signal) when possible (e.g., between instructions). 5. DMAC takes control of address, data, and control buses. 6. DMAC performs the data transfer directly between the I/O device and memory, incrementing the memory address and decrementing the word count for each word transferred. 7. Once the block transfer is complete, DMAC releases the bus and notifies the CPU via an interrupt. \* \*\*DMA Modes:\*\* \* \*\*Burst Mode:\*\* DMAC retains control of the bus until the entire block of data is transferred. Fastest DMA transfer but holds up the CPU for longer periods. \* \*\*Cycle Stealing Mode:\*\* DMAC requests and gains control of the bus for just one word transfer, then releases it. Repeats this process. Less interference with CPU execution but overall transfer takes longer due to repeated bus arbitration. \* \*\*(Transparent Mode):\*\* DMAC only transfers when CPU is not using the bus (e.g., during instruction decode). Slowest, no CPU interference.10. \*\*Q:\*\* Compare Asynchronous DRAMs and Synchronous DRAMs. (June 2023 Sup Q20a - 5 Marks) / What is a DRAM? Compare the two types of DRAMs, highlighting their differences. (July 2021 Q20a - 7 Marks) \*\*A:\*\* DRAM (Dynamic RAM) is the main type of semiconductor memory used for main memory. \* \*\*Asynchronous DRAM (Conventional DRAM):\*\* CPU memory requests (address, data, control signals like RAS, CAS, WE) are not tied to a common system clock. Memory responds as quickly as it can. Access time depends on internal delays. Performance limited by unpredictable timing and synchronization overhead. Examples: FPM (Fast Page Mode) DRAM, EDO (Extended Data Out) DRAM. \* \*\*Synchronous DRAM (SDRAM):\*\* All operations (addressing, data transfer, refreshing) are synchronized with the system clock. Allows for pipelined operations within the DRAM chip. Predictable timing enables higher clock speeds and data transfer rates. Interface includes clock signal, command inputs (CS, RAS, CAS, WE interpreted on clock edges). Examples: SDR SDRAM, DDR, DDR2, DDR3, DDR4, DDR5 SDRAM (Double Data Rate types transfer data on both clock edges). \* \*\*Differences:\*\* SDRAM is faster, has higher bandwidth, uses pipelining, and operates synchronously with the system clock, whereas Asynchronous DRAM is slower, less efficient, and operates asynchronously. SDRAM has largely replaced asynchronous DRAM in modern systems.11. \*\*Q:\*\* Explain the different cache mapping functions with an example for each. (June 2023 Sup Q20b - 9 Marks, June 2023 Reg Q20b - 8 Marks, July 2021 Q19a - 7 Marks, June 2022 Q20b - 9 Marks) \*\*A:\*\* Cache mapping functions determine how main memory blocks are placed into cache lines. \* \*\*Example Setup:\*\* Assume Cache size = 1KB (1024 bytes), Block size = 16 bytes. Number of cache lines = 1024 / 16 = 64 lines (indexed 0-63). Main Memory size = 64KB (65536 bytes). Memory blocks = 65536 / 16 = 4096 blocks (indexed 0-4095). Memory Address = 16 bits. Cache Line index = 6 bits (2^6=64). Block offset = 4 bits (2^4=16). Tag = 16 - 6 - 4 = 6 bits. \* \*\*1. Direct Mapping:\*\* Each memory block can only map to one specific cache line. \* Formula: \`Cache Line Index = (Memory Block Address) MOD (Number of Cache Lines)\` \* Example: Memory block 70 (binary 0100 0110) -> Cache Line Index = 70 MOD 64 = 6. Memory block 134 (binary 1000 0110) -> Cache Line Index = 134 MOD 64 = 6. Both map to line 6. \* Address Split: \`| Tag (6) | Index (6) | Offset (4) |\` \* Pros: Simple hardware, low cost. Cons: High conflict misses if frequently used blocks map to the same line (thrashing). \* \*\*2. Fully Associative Mapping:\*\* Any memory block can map to any cache line. \* Formula: No specific line determined by address. All lines are searched. \* Example: Memory block 70 can go into any free line (0-63). \* Address Split: \`| Tag (12) | Offset (4) |\` (Index is not used for placement) \* Pros: Most flexible, lowest conflict misses. Cons: Complex hardware (requires associative search/CAM for tag comparison across all lines), expensive, slower comparison. \* \*\*3. Set-Associative Mapping:\*\* A compromise. Cache lines are grouped into sets. Each memory block maps to a specific set, but can be placed in any line within that set. (N-way set-associative means N lines per set). \* Formula: \`Set Index = (Memory Block Address) MOD (Number of Sets)\` \* Example (2-way Set-Associative): Number of Sets = 64 lines / 2 lines/set = 32 sets (indexed 0-31). Memory Address = 16 bits. Set index = 5 bits (2^5=32). Tag = 16 - 5 - 4 = 7 bits. \* Memory block 70 (binary 0100 0110) -> Set Index = 70 MOD 32 = 6. Block 70 can go into either line within set 6. Memory block 134 (1000 0110) -> Set Index = 134 MOD 32 = 6. Block 134 maps to set 6. If block 70 is already in one line of set 6, block 134 can go into the other line. Only if both lines in set 6 are occupied and a third block mapping to set 6 arrives, a replacement is needed. \* Address Split: \`| Tag (7) | Set (5) | Offset (4) |\` \* Pros: Balances hardware cost and hit rate. Reduces conflict misses compared to direct mapping. Cons: More complex than direct mapping.12. \*\*Q:\*\* Explain the hit and miss condition occurring during the read and write operation on cache memory. Also give the importance of dirty bit during the writing operation. (June 2023 Reg Q19b - 8 Marks) \*\*A:\*\* \* \*\*Read Operation:\*\* \* \*\*Read Hit:\*\* CPU requests data. Address is checked against cache tags. If the corresponding block is found in the cache, data is read directly from the cache line. Fast access. \* \*\*Read Miss:\*\* Requested block is not in the cache. CPU stalls (or continues if non-blocking). Cache controller fetches the required block from main memory, loads it into a suitable cache line (using mapping function and replacement policy if needed), and then provides the requested data to the CPU. Slower access. \* \*\*Write Operation:\*\* \* \*\*Write Hit:\*\* CPU wants to write data to an address found in the cache. Policies dictate how this is handled: \* \*\*Write-Through:\*\* Data is written to both the cache line and the main memory simultaneously. Simple, ensures consistency, but slower due to main memory write. \* \*\*Write-Back:\*\* Data is written only to the cache line. The line is marked as "dirty" or "modified" using a \*\*Dirty Bit\*\*. Main memory is updated only when the dirty block is replaced from the cache. Faster writes, reduces memory traffic. \* \*\*Write Miss:\*\* CPU wants to write data to an address not in the cache. Policies: \* \*\*Write-Allocate (Fetch-on-Write):\*\* The block is first fetched from main memory into the cache, and then the write operation proceeds as a Write Hit (using Write-Through or Write-Back). Common approach. \* \*\*No-Write-Allocate (Write-Around):\*\* The data is written directly to main memory, bypassing the cache. Simpler, but doesn't leverage cache for subsequent reads of that block unless it's read later causing a read miss. \* \*\*Importance of Dirty Bit:\*\* Used only in Write-Back policy. It indicates whether the data in a cache line has been modified relative to main memory. When a block replacement is needed, if the dirty bit is set (1), the cache controller must write the modified block back to main memory before loading the new block. If the dirty bit is clear (0), the cache line can be overwritten directly as it's consistent with main memory. This optimizes write-back by avoiding unnecessary writes to main memory.---
